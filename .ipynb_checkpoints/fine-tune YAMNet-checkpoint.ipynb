{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to tensorflow model research directory for yamnet\n",
    "# https://github.com/tensorflow/models/tree/master/research/audioset\n",
    "yamnet_path = '/home/ubuntu/models/research/audioset/yamnet/'\n",
    "\n",
    "# path to downloaded yamnet weights\n",
    "# must be downloaded https://github.com/tensorflow/models/tree/master/research/audioset/yamnet\n",
    "weights_path = '/home/ubuntu/models/research/audioset/yamnet/yamnet.h5'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import tensorflow as tf\n",
    "os.sys.path.insert(0, yamnet_path)\n",
    "import yamnet\n",
    "import params\n",
    "from datagen_yamnet import DataGenerator, get_files_and_labels\n",
    "\n",
    "# directory storing the spectrogram inputs for each class\n",
    "train_dir = './train_set_patches/'\n",
    "\n",
    "# path to output model\n",
    "model_out = './saved_models/model'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get training data files and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the 'train_split' parameter below sets how much of the training data will be randomly sampled for test data\n",
    "files_train, files_val, labels = get_files_and_labels(train_dir, \n",
    "                                                    typ='npy',\n",
    "                                                    train_split=0.8)\n",
    "\n",
    "# if you want to use a separate folder with validation samples instead, do this:\n",
    "# files_train, _, labels class_dict = get_files_and_labels(train_dir, \n",
    "#                                                         typ='npy',\n",
    "#                                                         train_split=1)\n",
    "# files_val, _, _ = get_files_and_labels(test_dir, \n",
    "#                                         typ='npy',\n",
    "#                                         train_split=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build pre-trained yamnet and load weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = params.Params()                      \n",
    "yamnet_model = yamnet.yamnet_frames_model(params)\n",
    "yamnet_model.load_weights(weights_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build yamnet base model (backbone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = tf.keras.models.Model(yamnet_model.get_layer('reshape').input,\n",
    "                                   yamnet_model.get_layer('layer14/pointwise_conv/relu').output,\n",
    "                                   name='yamnet_base')\n",
    "\n",
    "base_model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define custom model top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (int(params.patch_window_seconds/params.stft_hop_seconds),\n",
    "               params.mel_bands)\n",
    "\n",
    "def get_model():\n",
    "    \n",
    "    inputs = tf.keras.layers.Input(input_shape)\n",
    "    \n",
    "    # call the base model\n",
    "    # set batch norm layers to inference mode\n",
    "    # https://keras.io/guides/transfer_learning/\n",
    "    x = base_model(inputs, training=False)\n",
    "    \n",
    "    # define model top\n",
    "    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "    x = tf.keras.layers.Dropout(0.5)(x) # for regularization\n",
    "    outputs = tf.keras.layers.Dense(len(labels), activation='softmax')(x)\n",
    "    \n",
    "    # create model\n",
    "    model = tf.keras.models.Model(inputs, outputs, name='custom_yamnet')\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = get_model()\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data generators\n",
    "# should use a larger batch size in a real case\n",
    "batch_size = 2\n",
    "\n",
    "train_generator = DataGenerator(files_train,\n",
    "                                labels,\n",
    "                                batch_size=batch_size)\n",
    "validation_generator = DataGenerator(files_val,\n",
    "                                    labels,\n",
    "                                    batch_size=batch_size)\n",
    "\n",
    "\n",
    "# define training callbacks\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(model_out+'.h5',\n",
    "                                                 monitor='val_loss', \n",
    "                                                 verbose=1,\n",
    "                                                 save_best_only=True, \n",
    "                                                 mode='auto')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# freeze base model \n",
    "model.get_layer('yamnet_base').trainable = False\n",
    "\n",
    "# compile model\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer=optimizer)\n",
    "\n",
    "model_history = model.fit(train_generator,\n",
    "                            steps_per_epoch = len(train_generator),\n",
    "                            epochs = 3,\n",
    "                            validation_data = validation_generator,\n",
    "                            validation_steps = len(validation_generator),\n",
    "                            verbose = 1,\n",
    "                            callbacks=[checkpoint])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optionally fine-tune the entire model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unfreeze base model \n",
    "model.get_layer('yamnet_base').trainable = False\n",
    "\n",
    "# recompile model and lower the learning rate\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-5)\n",
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer=optimizer)\n",
    "\n",
    "model_history = model.fit(train_generator,\n",
    "                            steps_per_epoch = len(train_generator),\n",
    "                            epochs = 3,\n",
    "                            validation_data = validation_generator,\n",
    "                            validation_steps = len(validation_generator),\n",
    "                            verbose = 1,\n",
    "                            callbacks=[checkpoint])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
